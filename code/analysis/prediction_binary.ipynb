{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting predictions for the unknown author from the best binary performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CvDda5pKxeDj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp25/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-07-20 21:39:31,248\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_predictions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g7KgVPlKttLf"
   },
   "outputs": [],
   "source": [
    "incerto_dir = os.path.join(os.getcwd(), '..', '..')\n",
    "poems_dir = os.path.join(incerto_dir, 'data', 'poems')\n",
    "figures_dir = os.path.join(incerto_dir, 'figures')\n",
    "output_dir = os.path.join(incerto_dir, 'output')\n",
    "classification_path = os.path.join(output_dir, 'classification-performance', f'binary_classification_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df_split = pd.read_csv(os.path.join(poems_dir, 'poems_split.csv'))\n",
    "p_df_whole = pd.read_csv(os.path.join(poems_dir, 'poems_whole.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "Cn7hRW9BLWBW",
    "outputId": "1ed1e418-f9f1-4432-fcc5-be870594649e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>author</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram type</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_f</th>\n",
       "      <th>num_f</th>\n",
       "      <th>scaler</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>AntonGiacomoCorso</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.649688</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier             author vectorizer ngram type ngram range  max_df  \\\n",
       "0      Logit  AntonGiacomoCorso      Count       Char     Bigrams     0.8   \n",
       "\n",
       "   min_df max_f  num_f          scaler  f1-score   type  \n",
       "0     0.0  None    259  StandardScaler  0.649688  Split  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(classification_path, keep_default_na=False)\n",
    "print(len(results_df))\n",
    "results_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>author</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram type</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_f</th>\n",
       "      <th>num_f</th>\n",
       "      <th>scaler</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logit</td>\n",
       "      <td>AntonGiacomoCorso</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.649688</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>AntonGiacomoCorso</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.518690</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>AntonGiacomoCorso</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.486660</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>AntonGiacomoCorso</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.486660</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logit</td>\n",
       "      <td>BartolomeoZacco</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.498877</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32395</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>ValerioSali</td>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Word</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>64</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.502253</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32396</th>\n",
       "      <td>kNN</td>\n",
       "      <td>VeronicaFranco</td>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Word</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>64</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.672914</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32397</th>\n",
       "      <td>Logit</td>\n",
       "      <td>VeronicaFranco</td>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Word</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>64</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32398</th>\n",
       "      <td>SVM</td>\n",
       "      <td>VeronicaFranco</td>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Word</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>64</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.575008</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32399</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>VeronicaFranco</td>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Word</td>\n",
       "      <td>Unigrams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1000</td>\n",
       "      <td>64</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.549347</td>\n",
       "      <td>Whole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         classifier             author vectorizer ngram type ngram range  \\\n",
       "0             Logit  AntonGiacomoCorso      Count       Char     Bigrams   \n",
       "1               kNN  AntonGiacomoCorso      Count       Char     Bigrams   \n",
       "2               SVM  AntonGiacomoCorso      Count       Char     Bigrams   \n",
       "3      RandomForest  AntonGiacomoCorso      Count       Char     Bigrams   \n",
       "4             Logit    BartolomeoZacco      Count       Char     Bigrams   \n",
       "...             ...                ...        ...        ...         ...   \n",
       "32395  RandomForest        ValerioSali      TfIdf       Word    Unigrams   \n",
       "32396           kNN     VeronicaFranco      TfIdf       Word    Unigrams   \n",
       "32397         Logit     VeronicaFranco      TfIdf       Word    Unigrams   \n",
       "32398           SVM     VeronicaFranco      TfIdf       Word    Unigrams   \n",
       "32399  RandomForest     VeronicaFranco      TfIdf       Word    Unigrams   \n",
       "\n",
       "       max_df  min_df max_f  num_f          scaler  f1-score   type  \n",
       "0         0.8     0.0  None    259  StandardScaler  0.649688  Split  \n",
       "1         0.8     0.0  None    259  StandardScaler  0.518690  Split  \n",
       "2         0.8     0.0  None    259  StandardScaler  0.486660  Split  \n",
       "3         0.8     0.0  None    259  StandardScaler  0.486660  Split  \n",
       "4         0.8     0.0  None    259  StandardScaler  0.498877  Split  \n",
       "...       ...     ...   ...    ...             ...       ...    ...  \n",
       "32395     1.0     0.2  1000     64              L2  0.502253  Whole  \n",
       "32396     1.0     0.2  1000     64              L2  0.672914  Whole  \n",
       "32397     1.0     0.2  1000     64              L2  0.487926  Whole  \n",
       "32398     1.0     0.2  1000     64              L2  0.575008  Whole  \n",
       "32399     1.0     0.2  1000     64              L2  0.549347  Whole  \n",
       "\n",
       "[32400 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models with F1-score (macro avg) > 0.7:\t 394\n",
      "Average f1-score:\t\t\t\t\t 0.73\n",
      "Number of models using split poems:\t\t\t 175\n"
     ]
    }
   ],
   "source": [
    "cond = (results_df['f1-score'] >= 0.7) & (results_df['author'] == 'VeronicaFranco')\n",
    "franco_top = results_df.loc[cond]\n",
    "print('Number of models with F1-score (macro avg) > 0.7:\\t', len(franco_top))\n",
    "print('Average f1-score:\\t\\t\\t\\t\\t', round(franco_top['f1-score'].mean(), 2))\n",
    "print('Number of models using split poems:\\t\\t\\t', len(franco_top.loc[franco_top['type'] == 'Split']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models with F1-score (macro avg) > 0.7:\t 158\n",
      "Authors the models are trained to classify:\t\t ['Petrarca']\n",
      "Average f1-score:\t\t\t\t\t 0.75\n",
      "Number of models using split poems:\t\t\t 42\n"
     ]
    }
   ],
   "source": [
    "cond = (results_df['f1-score'] >= 0.7) & (results_df['author'] == 'Petrarca')\n",
    "petrarca_top = results_df.loc[cond].copy()\n",
    "print('Number of models with F1-score (macro avg) > 0.7:\\t', len(petrarca_top))\n",
    "print('Authors the models are trained to classify:\\t\\t', petrarca_top['author'].unique())\n",
    "print('Average f1-score:\\t\\t\\t\\t\\t', round(petrarca_top['f1-score'].mean(), 2))\n",
    "print('Number of models using split poems:\\t\\t\\t', len(petrarca_top.loc[petrarca_top['type'] == 'Split']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XquZeoDJryy",
    "outputId": "e6714f8a-b52f-4cfc-947d-68db572eb47d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models with F1-score (macro avg) > 0.7:\t 140\n",
      "Authors the models are trained to classify:\t\t ['MaffioVenier' 'DomenicoVenier' 'OrsattoGiustinian' 'PietroBembo'\n",
      " 'MuzioManfredi']\n",
      "Average f1-score:\t\t\t\t\t 0.73\n",
      "Number of models using split poems:\t\t\t 94\n"
     ]
    }
   ],
   "source": [
    "cond = (results_df['f1-score'] >= 0.7) & (results_df['author'] != 'VeronicaFranco') & (results_df['author'] != 'Petrarca')\n",
    "other_top = results_df.loc[cond].copy()\n",
    "print('Number of models with F1-score (macro avg) > 0.7:\\t', len(other_top))\n",
    "print('Authors the models are trained to classify:\\t\\t', other_top['author'].unique())\n",
    "print('Average f1-score:\\t\\t\\t\\t\\t', round(other_top['f1-score'].mean(), 2))\n",
    "print('Number of models using split poems:\\t\\t\\t', len(other_top.loc[other_top['type'] == 'Split']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>author</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram type</th>\n",
       "      <th>ngram range</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_f</th>\n",
       "      <th>num_f</th>\n",
       "      <th>scaler</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>259</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.713763</td>\n",
       "      <td>Split</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classifier        author vectorizer ngram type ngram range  max_df  min_df  \\\n",
       "20      Logit  MaffioVenier      Count       Char     Bigrams     0.8     0.0   \n",
       "\n",
       "   max_f  num_f          scaler  f1-score   type  \n",
       "20  None    259  StandardScaler  0.713763  Split  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models = results_df.loc[results_df['f1-score'] >= 0.7]\n",
    "print(len(top_models))\n",
    "top_models[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaffioVenier 49\n",
      "VeronicaFranco 394\n",
      "Petrarca 158\n",
      "DomenicoVenier 36\n",
      "OrsattoGiustinian 9\n",
      "PietroBembo 4\n",
      "MuzioManfredi 42\n"
     ]
    }
   ],
   "source": [
    "for author in top_models.author.unique():\n",
    "  n = len(results_df[(results_df['author'] == author) & (results_df['f1-score'] >= 0.7)])\n",
    "  print(author, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_EByD0V8Mkt",
    "tags": []
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FjkBhHcy2-0l"
   },
   "outputs": [],
   "source": [
    "ngram_range_d = {'Unigrams': (1,1),\n",
    "                 'Bigrams': (2,2),\n",
    "                 'Trigrams': (3,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "WPGytODz8niF"
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "  'RandomForest': RandomForestClassifier(),\n",
    "  'kNN': KNeighborsClassifier(),\n",
    "  'Logit': LogisticRegression(),\n",
    "  'SVM': SVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4kOD_dGivQ79"
   },
   "outputs": [],
   "source": [
    "scalers = {'StandardScaler': StandardScaler(),\n",
    "           'L1': Normalizer(norm='l1'),\n",
    "           'L2': Normalizer(norm='l2')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UKhUQ_b9cugY"
   },
   "outputs": [],
   "source": [
    "def build_vectorizer(_typ, _ngram, _max, _min, _max_f):\n",
    "\n",
    "    if _max_f == 'None':\n",
    "        _max_f = None\n",
    "    else:\n",
    "        _max_f = int(_max_f)\n",
    "\n",
    "    if _typ == 'Count':\n",
    "        vec = CountVectorizer(input='content',\n",
    "                    encoding='utf-8',\n",
    "                    lowercase=True,\n",
    "                    analyzer=_ngram[0].lower(),\n",
    "                    ngram_range=_ngram[2],\n",
    "                    max_df=_max,\n",
    "                    min_df=_min,\n",
    "                    max_features=_max_f)\n",
    "\n",
    "    elif _typ == 'TfIdf':\n",
    "        vec = TfidfVectorizer(input='content',\n",
    "                    encoding='utf-8',\n",
    "                    lowercase=True,\n",
    "                    analyzer=_ngram[0].lower(),\n",
    "                    ngram_range=_ngram[2],\n",
    "                    max_df=_max,\n",
    "                    min_df=_min,\n",
    "                    max_features=_max_f,\n",
    "                    norm=None)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v9Ze2-jyXK7q"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    report_d = classification_report(test_labels, predictions, zero_division=0, output_dict=True)\n",
    "    f1score = report_d['macro avg']['f1-score']\n",
    "    f1score_1 = report_d['1']['f1-score']\n",
    "\n",
    "    return f1score, f1score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 21:39:33,971\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "if run_predictions == True:\n",
    "    ray.init(num_cpus=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "wSkLZTkJ1vyU",
    "outputId": "70e05a8b-b0ba-4431-f4fd-9df2015cfa6d"
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_predictions(path, row, p_df):\n",
    "\n",
    "  ngram_range = row['ngram range']\n",
    "  author = row['author']\n",
    "  classifier = row['classifier']\n",
    "  scaler = row['scaler']\n",
    "  cv_score = row['f1-score']\n",
    "\n",
    "  if row['ngram type'] == 'Char':\n",
    "      poems = [re.sub(r'\\s+', '', x) for x in p_df['poem'].tolist()]\n",
    "  elif row['ngram type'] == 'Word':\n",
    "      poems = p_df['poem'].tolist()\n",
    "  \n",
    "  # vectorize poems\n",
    "  vectorizer = build_vectorizer(row['vectorizer'], [row['ngram type'], ngram_range, ngram_range_d[ngram_range]], row['max_df'], row['min_df'], row['max_f'])\n",
    "  X = vectorizer.fit_transform(poems)\n",
    "  scaled_X = scalers[scaler].fit_transform(X.toarray())\n",
    "  # final_X = pd.DataFrame(scaled_X, columns=vectorizer.get_feature_names_out()) \n",
    "  # df = p_df[['label', 'author']].merge(final_X, left_index=True, right_index=True)\n",
    "\n",
    "  # select rows for training and testing\n",
    "  known_df = p_df.loc[p_df['author'] != 'UnknownAuthor']\n",
    "  known_X = scaled_X[known_df.index, :]\n",
    "  known_y = known_df['author'].map(lambda x: 1 if x==author else 0).tolist()\n",
    "  # X_train, X_test, y_train, y_test = train_test_split(known_X, known_y, test_size = 0.25, random_state = 42)\n",
    "  \n",
    "  # training and testing\n",
    "  # cl = classifiers[classifier].fit(X_train, y_train)\n",
    "  cl = classifiers[classifier].fit(known_X, known_y)\n",
    "  # f1, f1_1 = evaluate(cl, X_test, y_test)\n",
    "\n",
    "  # selecting poems to predict\n",
    "  unknown_df = p_df.loc[p_df['author'] == 'UnknownAuthor']\n",
    "  unknown_labels = unknown_df['label'].tolist()\n",
    "  unknown_X = scaled_X[unknown_df.index, :]\n",
    "\n",
    "  predictions = cl.predict(unknown_X)\n",
    "  labeled_predictions = list(zip(unknown_labels, predictions))\n",
    "\n",
    "  for tuple in labeled_predictions:\n",
    "    with open(path, 'a') as csvfile:\n",
    "      csvwriter = csv.writer(csvfile)\n",
    "      csvwriter.writerow((tuple[0], tuple[1],\n",
    "                classifier, author, row['vectorizer'],\n",
    "                row['ngram type'], ngram_range,\n",
    "                row['max_df'], row['min_df'], row['max_f'], row['num_f'], row['scaler'],\n",
    "                row['type'], 'Binary',\n",
    "                cv_score))#, f1, f1_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dir = os.path.join(incerto_dir, 'output', 'predictions')\n",
    "predictions_path = os.path.join(predictions_dir, 'predictions_binary2.csv')\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.makedirs(predictions_dir)\n",
    "if not os.path.exists(predictions_path):\n",
    "    with open(predictions_path, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(('label', 'prediction',\n",
    "                            'classifier', 'author', 'vectorizer',\n",
    "                            'ngram_type', 'ngram_range',\n",
    "                            'max_df', 'min_df', 'max_f', 'num_f', 'scaler',\n",
    "                            'poem_type', 'classifier_type',\n",
    "                            'cv_f1-score'))#, 'f1-score', 'f1-score_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = []\n",
    "if run_predictions == True:\n",
    "    for _index, _row in top_models.iterrows():\n",
    "        if _row['type'] == 'Split':\n",
    "            _p_df = p_df_split\n",
    "        elif _row['type'] == 'Whole':\n",
    "            _p_df = p_df_whole\n",
    "        futures.append(do_predictions.remote(predictions_path, _row, _p_df))\n",
    "        # futures.append(do_predictions(predictions_path, _row, _p_df))\n",
    "\n",
    "    results = ray.get(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>classifier</th>\n",
       "      <th>author</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>ngram_type</th>\n",
       "      <th>ngram_range</th>\n",
       "      <th>max_df</th>\n",
       "      <th>min_df</th>\n",
       "      <th>max_f</th>\n",
       "      <th>num_f</th>\n",
       "      <th>scaler</th>\n",
       "      <th>poem_type</th>\n",
       "      <th>classifier_type</th>\n",
       "      <th>cv_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UnknownAuthor_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Split</td>\n",
       "      <td>Binary</td>\n",
       "      <td>0.722234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UnknownAuthor_1_2</td>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Split</td>\n",
       "      <td>Binary</td>\n",
       "      <td>0.722234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UnknownAuthor_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Split</td>\n",
       "      <td>Binary</td>\n",
       "      <td>0.700967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UnknownAuthor_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>157</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Split</td>\n",
       "      <td>Binary</td>\n",
       "      <td>0.700967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnknownAuthor_1_3</td>\n",
       "      <td>0</td>\n",
       "      <td>Logit</td>\n",
       "      <td>MaffioVenier</td>\n",
       "      <td>Count</td>\n",
       "      <td>Char</td>\n",
       "      <td>Bigrams</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>Split</td>\n",
       "      <td>Binary</td>\n",
       "      <td>0.722234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  prediction classifier        author vectorizer  \\\n",
       "0  UnknownAuthor_1_1           0      Logit  MaffioVenier      Count   \n",
       "1  UnknownAuthor_1_2           0      Logit  MaffioVenier      Count   \n",
       "2  UnknownAuthor_1_1           0      Logit  MaffioVenier      Count   \n",
       "3  UnknownAuthor_1_1           0      Logit  MaffioVenier      Count   \n",
       "4  UnknownAuthor_1_3           0      Logit  MaffioVenier      Count   \n",
       "\n",
       "  ngram_type ngram_range  max_df  min_df   max_f  num_f          scaler  \\\n",
       "0       Char     Bigrams     0.8     0.2     NaN    137  StandardScaler   \n",
       "1       Char     Bigrams     0.8     0.2     NaN    137  StandardScaler   \n",
       "2       Char     Bigrams     0.8     0.1     NaN    157  StandardScaler   \n",
       "3       Char     Bigrams     0.8     0.1  1000.0    157  StandardScaler   \n",
       "4       Char     Bigrams     0.8     0.2     NaN    137  StandardScaler   \n",
       "\n",
       "  poem_type classifier_type  cv_f1-score  \n",
       "0     Split          Binary     0.722234  \n",
       "1     Split          Binary     0.722234  \n",
       "2     Split          Binary     0.700967  \n",
       "3     Split          Binary     0.700967  \n",
       "4     Split          Binary     0.722234  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.read_csv(predictions_path)\n",
    "print(len(predictions_df))\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jBRl-OO3yLe4",
    "LfE3DPLEyLe4",
    "4acuH_GkyLe4"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
