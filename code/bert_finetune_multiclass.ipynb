{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHbxcRd3I9P6"
   },
   "source": [
    "# Fine-tuning BERT for Multi-class Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1679693481190,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "dXTjXMxTu3mo",
    "outputId": "516f43f9-6cc2-43f0-801f-4121a492ff32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount the Google drive for access to files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhjG5GG1uKLw"
   },
   "outputs": [],
   "source": [
    "# Basic Python modules\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For machine learning tools and evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split\n",
    "\n",
    "# For deep learning\n",
    "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDPCU9weVwSW"
   },
   "outputs": [],
   "source": [
    "incerto_dir = '/content/drive/MyDrive/incerto-autore'\n",
    "new_poems_dir = os.path.join(incerto_dir, 'data', 'poems')\n",
    "poems_split_df = pd.read_csv(os.path.join(new_poems_dir, 'poems_split.csv'))\n",
    "len(poems_split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3432,
     "status": "ok",
     "timestamp": 1679693487900,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "VSzpsiI61kDI",
    "outputId": "bfec087b-1b97-4936-fd9b-41e1258735de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27gBNNuBugj3"
   },
   "outputs": [],
   "source": [
    "# using DistilBERT for testing --> can switch to BERT once set up\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMONncVvuo1j"
   },
   "outputs": [],
   "source": [
    "# Choose the GPU we want to process this script\n",
    "device_name = 'cuda'\n",
    "\n",
    "# Choose the BERT model that we want to use (make sure to keep the cased/uncased consistent)\n",
    "#model = 'dbmdz/bert-base-italian-xxl-uncased'\n",
    "model = os.path.join(incerto_dir, 'contbertoldo-all', 'checkpoint')\n",
    "\n",
    "# This is the maximum number of tokens in any document sent to BERT\n",
    "max_length = 512                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5IKdrWBzvl7"
   },
   "outputs": [],
   "source": [
    "if 'contbertoldo' in model:\n",
    "  finetuned_path = os.path.join(incerto_dir, 'output','finetuned-models', 'multi-class', 'bertoldo')\n",
    "elif 'italian':\n",
    "  finetuned_path = os.path.join(incerto_dir, 'output','finetuned-models', 'multi-class', 'bert-ita')\n",
    "if not os.path.exists(finetuned_path):\n",
    "  os.makedirs(finetuned_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "104t5xjlCTNT"
   },
   "source": [
    "### BERT setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679693490060,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "D2sEBx03oG-j",
    "outputId": "c93f3d66-0b07-413a-8393-0911313efac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = poems_split_df.loc[poems_split_df['author'] != 'Unknown']\n",
    "len(annotations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679693490061,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "s-x4QLzpRng4",
    "outputId": "4b99d23b-a3e2-4ceb-a024-23aa21c88cac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y train Counter({'Franco': 174, 'Petrarca': 121, 'AntonGiacomoCorso': 45, 'CelioMagno': 39, 'PietroBembo': 39, 'DomenicoVenier': 31, 'GiorgioGradenigo': 9, 'MarcoVenier': 8})\n",
      "Y test Counter({'Franco': 50, 'Petrarca': 42, 'CelioMagno': 18, 'PietroBembo': 15, 'AntonGiacomoCorso': 14, 'DomenicoVenier': 9, 'MarcoVenier': 4, 'GiorgioGradenigo': 4})\n",
      "['Mie venture al venir son tarde e pigre La speme incerta e l desir monta e cresce Onde l lasciar e l aspettar m incresce E poi al partir son piu levi che tigre Lasso le nevi fien tepide e nigre E l mar senz onda e per l alpe ogni pesce E corcherassi l Sol la oltre ond esce D un medesimo fonte Eufrate e Tigre Prima ch i trovi in cio pace ne triegua O Amor o Madonna altr uso impari Che m hanno congiurato a torto incontra E s i ho alcun dolce e dopo tanti amari Che per disdegno il gusto si dilegua Altro mai di lor gratie non m incontra', 'Questa col canto suo frenar s udio Spesso i fiumi nel corso e i monti e i sassi Seguaci far di sua rara dolcezza Questa di morte anchor le leggi sprezza Et ne l Inferno aperta strada fassi Quinci a gli spirti lassi Da le cure del mondo have ristoro Giove nel sommo choro Mentre Febo cantando in dolci note L harmonia tempra a le celesti rote Di quei ch a tal favor degnan le stelle Un te ne scegli e tel procaccia amico Che del Tempo nemico Ei sol darti potra vittoria e palma', 'Amor con sue promesse lusingando Mi ricondusse a la prigione antica E die le chiavi a quella mia nemica Ch ancor me di me stesso tiene in bando Non me n avidi lasso se non quando Fui in lor forza e hor con gran fatica Chi l credera perche giurando l dica In liberta ritorno sospirando E come vero prigionero afflitto De le catene mie gran parte porto E l cor ne gli occhi e ne la fronte ho scritto Quando sarai del mio colore accorto Dirai S i guardo e giudico ben dritto Questi havea poco andare ad esser morto']\n"
     ]
    }
   ],
   "source": [
    "X = annotations_df['poem'].tolist()\n",
    "y = annotations_df['author'].tolist()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "print('Y train', Counter(y_train))\n",
    "print('Y test', Counter(y_test))\n",
    "print(X_test[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1679693490061,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "UhR76M8FXXAo",
    "outputId": "6a80c8a0-03af-46b1-ddfb-897be5dfc429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AntonGiacomoCorso': 0, 'CelioMagno': 1, 'DomenicoVenier': 2, 'Franco': 3, 'GiorgioGradenigo': 4, 'MarcoVenier': 5, 'Petrarca': 6, 'PietroBembo': 7}\n",
      "{0: 'AntonGiacomoCorso', 1: 'CelioMagno', 2: 'DomenicoVenier', 3: 'Franco', 4: 'GiorgioGradenigo', 5: 'MarcoVenier', 6: 'Petrarca', 7: 'PietroBembo'}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = list(set(annotations_df['author'].tolist()))\n",
    "unique_labels.sort()\n",
    "label2id = {label: id for id, label in enumerate(unique_labels)}\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXAfCovWy_9p"
   },
   "outputs": [],
   "source": [
    "# load the encoder/tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTBZ0KCvzwIN"
   },
   "outputs": [],
   "source": [
    "# class for Torch dataset\n",
    "class SCDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFLoD8Xf0BC2"
   },
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    learning_rate=5e-5,              # initial learning rate for Adam optimizer\n",
    "    warmup_steps=70,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17044,
     "status": "ok",
     "timestamp": 1679693509378,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "gaySsuc80JRy",
    "outputId": "d4fc6dc4-1299-4fcd-b781-f59dd4a9c88a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /content/drive/MyDrive/incerto-autore/contbertoldo-all/checkpoint were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/incerto-autore/contbertoldo-all/checkpoint and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(model,  num_labels=len(id2label)).to(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1679693509378,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "wRT1dNcWXBxg",
    "outputId": "a136ce67-07a4-4fce-b3bc-6e7161929a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(model.config.num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJAQfcvI0L_e"
   },
   "outputs": [],
   "source": [
    "# Define a custom evaluation function (this could be changes to return accuracy metrics)\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwNt4uRXGTHO"
   },
   "source": [
    "## Classification task setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3966,
     "status": "ok",
     "timestamp": 1679693513331,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "IPath3csXmbG",
    "outputId": "4ae2d14f-6815-471e-c272-01bce878d3cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "# Pass training/testing sentences to tokenizer, truncate them if over max length, and add padding (PAD tokens up to 512)\n",
    "train_encodings = tokenizer(X_train,  truncation=True, padding=True, max_length=max_length)\n",
    "test_encodings = tokenizer(X_test,  truncation=True, padding=True, max_length=max_length)\n",
    "\n",
    "# Encoding labels as integer numbers\n",
    "train_labels_encoded = [label2id[y] for y in y_train]\n",
    "test_labels_encoded  = [label2id[y] for y in y_test]\n",
    "print(len(set(train_labels_encoded)),len(set(test_labels_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GEgWW9I6Rr7R"
   },
   "outputs": [],
   "source": [
    "# Combine encoded text and labels into a torch dataset object.\n",
    "train_dataset = SCDataset(train_encodings, train_labels_encoded)\n",
    "test_dataset = SCDataset(test_encodings, test_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzqqNQjpRvgE"
   },
   "outputs": [],
   "source": [
    "# Create the trainer object based on what we've set up prior to this point! This combines our model, training_args, train_dataset and test_dataset, and custom evaluation function compute_metrics.\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,            # evaluation dataset\n",
    "    compute_metrics=compute_metrics      # custom evaluation function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "executionInfo": {
     "elapsed": 288182,
     "status": "ok",
     "timestamp": 1679693801492,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "JlscYOyWRwgA",
    "outputId": "50577b51-9adc-4dba-c21b-f0fe90e5ffc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 04:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.968800</td>\n",
       "      <td>1.879503</td>\n",
       "      <td>0.320513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.773500</td>\n",
       "      <td>1.766240</td>\n",
       "      <td>0.320513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.746700</td>\n",
       "      <td>1.744009</td>\n",
       "      <td>0.320513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.727900</td>\n",
       "      <td>1.633460</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.439100</td>\n",
       "      <td>1.536915</td>\n",
       "      <td>0.493590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.523600</td>\n",
       "      <td>1.437110</td>\n",
       "      <td>0.532051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.308200</td>\n",
       "      <td>1.291756</td>\n",
       "      <td>0.557692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.154400</td>\n",
       "      <td>1.300723</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.114200</td>\n",
       "      <td>1.152556</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>1.255529</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>1.165414</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>0.621795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.571300</td>\n",
       "      <td>0.959522</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.596300</td>\n",
       "      <td>1.128629</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>1.058626</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=1.1838725725809733, metrics={'train_runtime': 287.1846, 'train_samples_per_second': 8.113, 'train_steps_per_second': 0.522, 'total_flos': 613081784893440.0, 'train_loss': 1.1838725725809733, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model on our dataset/labels. The trainer object will periodically output the state of the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "executionInfo": {
     "elapsed": 3901,
     "status": "ok",
     "timestamp": 1679693805390,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "_4t8wZY8RzD2",
    "outputId": "761e5644-7f62-498a-c806-0c178dbd5d26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0586260557174683,\n",
       " 'eval_accuracy': 0.6538461538461539,\n",
       " 'eval_runtime': 4.996,\n",
       " 'eval_samples_per_second': 31.225,\n",
       " 'eval_steps_per_second': 1.601,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# built in evaluation function\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAUjVKaDR0oX"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save_pretrained(finetuned_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1679693811981,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "TMUUrYpOR3NI",
    "outputId": "6cc917b4-c016-408b-9eb3-f99e58b4f6c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Franco': 50, 'Petrarca': 42, 'CelioMagno': 18, 'PietroBembo': 15, 'AntonGiacomoCorso': 14, 'DomenicoVenier': 9, 'MarcoVenier': 4, 'GiorgioGradenigo': 4})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 5768,
     "status": "ok",
     "timestamp": 1679693817728,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "SUeAxZFcR4dD",
    "outputId": "5878608f-47cb-4d81-82fb-9067621779ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_labels = trainer.predict(test_dataset)\n",
    "actual_predicted_labels = predicted_labels.predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1679693817729,
     "user": {
      "displayName": "Federica Bologna",
      "userId": "16530074403271623482"
     },
     "user_tz": 240
    },
    "id": "_afBA6OeR5tu",
    "outputId": "5cbdcefe-4990-4a84-a75e-9a44a0d33b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.57      0.40        14\n",
      "           1       0.60      0.67      0.63        18\n",
      "           2       0.33      0.11      0.17         9\n",
      "           3       0.77      0.94      0.85        50\n",
      "           4       0.00      0.00      0.00         4\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.89      0.60      0.71        42\n",
      "           7       0.50      0.60      0.55        15\n",
      "\n",
      "    accuracy                           0.65       156\n",
      "   macro avg       0.43      0.44      0.41       156\n",
      "weighted avg       0.65      0.65      0.63       156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(predicted_labels.label_ids.flatten(), actual_predicted_labels.flatten(), output_dict=True)\n",
    "print(classification_report(predicted_labels.label_ids.flatten(), actual_predicted_labels.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5rINvGpVwSX"
   },
   "outputs": [],
   "source": [
    "# New + simple save of classification report\n",
    "class_report_df = pd.DataFrame(class_report).transpose()\n",
    "class_report_df.to_csv(os.path.join(finetuned_path, 'classification_report.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hq8DGILd2-Sa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "0847cda728ef3e0f335e7e94b5a043d9a0fda1c620343fc6302f7013063303dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
